{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from math import log,floor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "# colors for plot\n",
    "deep_saffron = '#FF9933'\n",
    "air_force_blue = '#5D8AA8'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "================================= MAIN CLASS ==================================\n",
    "\"\"\"\n",
    "\n",
    "class SPOT:\n",
    "    \"\"\"\n",
    "    This class allows to run SPOT algorithm on univariate dataset (upper-bound)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    proba : float\n",
    "        Detection level (risk), chosen by the user\n",
    "        \n",
    "    extreme_quantile : float\n",
    "        current threshold (bound between normal and abnormal events)\n",
    "        \n",
    "    data : numpy.array\n",
    "        stream\n",
    "    \n",
    "    init_data : numpy.array\n",
    "        initial batch of observations (for the calibration/initialization step)\n",
    "    \n",
    "    init_threshold : float\n",
    "        initial threshold computed during the calibration step\n",
    "    \n",
    "    peaks : numpy.array\n",
    "        array of peaks (excesses above the initial threshold)\n",
    "    \n",
    "    n : int\n",
    "        number of observed values\n",
    "    \n",
    "    Nt : int\n",
    "        number of observed peaks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, q = 1e-4):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\t    Parameters\n",
    "\t    ----------\n",
    "\t    q\n",
    "\t\t    Detection level (risk)\n",
    "\t\n",
    "\t    Returns\n",
    "\t    ----------\n",
    "    \tSPOT object\n",
    "        \"\"\"\n",
    "        self.proba = q\n",
    "        self.extreme_quantile = None\n",
    "        self.data = None\n",
    "        self.init_data = None\n",
    "        self.init_threshold = None\n",
    "        self.peaks = None\n",
    "        self.n = 0\n",
    "        self.Nt = 0\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = ''\n",
    "        s += 'Streaming Peaks-Over-Threshold Object\\n'\n",
    "        s += 'Detection level q = %s\\n' % self.proba\n",
    "        if self.data is not None:\n",
    "            s += 'Data imported : Yes\\n'\n",
    "            s += '\\t initialization  : %s values\\n' % self.init_data.size\n",
    "            s += '\\t stream : %s values\\n' % self.data.size\n",
    "        else:\n",
    "            s += 'Data imported : No\\n'\n",
    "            return s\n",
    "            \n",
    "        if self.n == 0:\n",
    "            s += 'Algorithm initialized : No\\n'\n",
    "        else:\n",
    "            s += 'Algorithm initialized : Yes\\n'\n",
    "            s += '\\t initial threshold : %s\\n' % self.init_threshold\n",
    "            \n",
    "            r = self.n-self.init_data.size\n",
    "            if r > 0:\n",
    "                s += 'Algorithm run : Yes\\n'\n",
    "                s += '\\t number of observations : %s (%.2f %%)\\n' % (r,100*r/self.n)\n",
    "            else:\n",
    "                s += '\\t number of peaks  : %s\\n' % self.Nt\n",
    "                s += '\\t extreme quantile : %s\\n' % self.extreme_quantile\n",
    "                s += 'Algorithm run : No\\n'\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    def fit(self,init_data,data):\n",
    "        \"\"\"\n",
    "        Import data to SPOT object\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    init_data : list, numpy.array or pandas.Series\n",
    "\t\t    initial batch to calibrate the algorithm\n",
    "            \n",
    "        data : numpy.array\n",
    "\t\t    data for the run (list, np.array or pd.series)\n",
    "\t\n",
    "        \"\"\"\n",
    "        if isinstance(data,list):\n",
    "            self.data = np.array(data)\n",
    "        elif isinstance(data,np.ndarray):\n",
    "            self.data = data\n",
    "        elif isinstance(data,pd.Series):\n",
    "            self.data = data.values\n",
    "        else:\n",
    "            print('This data format (%s) is not supported' % type(data))\n",
    "            return\n",
    "            \n",
    "        if isinstance(init_data,list):\n",
    "            self.init_data = np.array(init_data)\n",
    "        elif isinstance(init_data,np.ndarray):\n",
    "            self.init_data = init_data\n",
    "        elif isinstance(init_data,pd.Series):\n",
    "            self.init_data = init_data.values\n",
    "        elif isinstance(init_data,int):\n",
    "            self.init_data = self.data[:init_data]\n",
    "            self.data = self.data[init_data:]\n",
    "        elif isinstance(init_data,float) & (init_data<1) & (init_data>0):\n",
    "            r = int(init_data*data.size)\n",
    "            self.init_data = self.data[:r]\n",
    "            self.data = self.data[r:]\n",
    "        else:\n",
    "            print('The initial data cannot be set')\n",
    "            return\n",
    "        \n",
    "    def add(self,data):\n",
    "        \"\"\"\n",
    "        This function allows to append data to the already fitted data\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    data : list, numpy.array, pandas.Series\n",
    "\t\t    data to append\n",
    "        \"\"\"\n",
    "        if isinstance(data,list):\n",
    "            data = np.array(data)\n",
    "        elif isinstance(data,np.ndarray):\n",
    "            data = data\n",
    "        elif isinstance(data,pd.Series):\n",
    "            data = data.values\n",
    "        else:\n",
    "            print('This data format (%s) is not supported' % type(data))\n",
    "            return\n",
    "        \n",
    "        self.data = np.append(self.data,data)\n",
    "        return\n",
    "    \n",
    "    def initialize(self, level = 0.98, verbose = True):\n",
    "        \"\"\"\n",
    "        Run the calibration (initialization) step\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "        level : float\n",
    "            (default 0.98) Probability associated with the initial threshold t \n",
    "\t    verbose : bool\n",
    "\t\t    (default = True) If True, gives details about the batch initialization\n",
    "        \"\"\"\n",
    "        level = level-floor(level)\n",
    "        \n",
    "        n_init = self.init_data.size\n",
    "        \n",
    "        S = np.sort(self.init_data)     # we sort X to get the empirical quantile\n",
    "        self.init_threshold = S[int(level*n_init)] # t is fixed for the whole algorithm\n",
    "\n",
    "        # initial peaks\n",
    "        self.peaks = self.init_data[self.init_data>self.init_threshold]-self.init_threshold \n",
    "        self.Nt = self.peaks.size\n",
    "        self.n = n_init\n",
    "        \n",
    "        if verbose:\n",
    "            print('Initial threshold : %s' % self.init_threshold)\n",
    "            print('Number of peaks : %s' % self.Nt)\n",
    "            print('Grimshaw maximum log-likelihood estimation ... ', end = '')\n",
    "            \n",
    "        g,s,l = self._grimshaw()\n",
    "        self.extreme_quantile = self._quantile(g,s)\n",
    "        \n",
    "        if verbose:\n",
    "            print('[done]')\n",
    "            print('\\t'+chr(0x03B3) + ' = ' + str(g))\n",
    "            print('\\t'+chr(0x03C3) + ' = ' + str(s))\n",
    "            print('\\tL = ' + str(l))\n",
    "            print('Extreme quantile (probability = %s): %s' % (self.proba,self.extreme_quantile))\n",
    "        \n",
    "        return \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _rootsFinder(fun,jac,bounds,npoints,method):\n",
    "        \"\"\"\n",
    "        Find possible roots of a scalar function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fun : function\n",
    "\t\t    scalar function \n",
    "        jac : function\n",
    "            first order derivative of the function  \n",
    "        bounds : tuple\n",
    "            (min,max) interval for the roots search    \n",
    "        npoints : int\n",
    "            maximum number of roots to output      \n",
    "        method : str\n",
    "            'regular' : regular sample of the search interval, 'random' : uniform (distribution) sample of the search interval\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        numpy.array\n",
    "            possible roots of the function\n",
    "        \"\"\"\n",
    "        if method == 'regular':\n",
    "            step = (bounds[1]-bounds[0])/(npoints+1)\n",
    "            X0 = np.arange(bounds[0]+step,bounds[1],step)\n",
    "        elif method == 'random':\n",
    "            X0 = np.random.uniform(bounds[0],bounds[1],npoints)\n",
    "        \n",
    "        def objFun(X,f,jac):\n",
    "            g = 0\n",
    "            j = np.zeros(X.shape)\n",
    "            i = 0\n",
    "            for x in X:\n",
    "                fx = f(x)\n",
    "                g = g+fx**2\n",
    "                j[i] = 2*fx*jac(x)\n",
    "                i = i+1\n",
    "            return g,j\n",
    "        \n",
    "        opt = minimize(lambda X:objFun(X,fun,jac), X0, \n",
    "                       method='L-BFGS-B', \n",
    "                       jac=True, bounds=[bounds]*len(X0))\n",
    "        \n",
    "        X = opt.x\n",
    "        np.round(X,decimals = 5)\n",
    "        return np.unique(X)\n",
    "    \n",
    "    \n",
    "    def _log_likelihood(Y,gamma,sigma):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood for the Generalized Pareto Distribution (μ=0)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Y : numpy.array\n",
    "\t\t    observations\n",
    "        gamma : float\n",
    "            GPD index parameter\n",
    "        sigma : float\n",
    "            GPD scale parameter (>0)   \n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            log-likelihood of the sample Y to be drawn from a GPD(γ,σ,μ=0)\n",
    "        \"\"\"\n",
    "        n = Y.size\n",
    "        if gamma != 0:\n",
    "            tau = gamma/sigma\n",
    "            L = -n * log(sigma) - ( 1 + (1/gamma) ) * ( np.log(1+tau*Y) ).sum()\n",
    "        else:\n",
    "            L = n * ( 1 + log(Y.mean()) )\n",
    "        return L\n",
    "\n",
    "\n",
    "    def _grimshaw(self,epsilon = 1e-8, n_points = 10):\n",
    "        \"\"\"\n",
    "        Compute the GPD parameters estimation with the Grimshaw's trick\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        epsilon : float\n",
    "\t\t    numerical parameter to perform (default : 1e-8)\n",
    "        n_points : int\n",
    "            maximum number of candidates for maximum likelihood (default : 10)\n",
    "        Returns\n",
    "        ----------\n",
    "        gamma_best,sigma_best,ll_best\n",
    "            gamma estimates, sigma estimates and corresponding log-likelihood\n",
    "        \"\"\"\n",
    "        def u(s):\n",
    "            return 1 + np.log(s).mean()\n",
    "            \n",
    "        def v(s):\n",
    "            return np.mean(1/s)\n",
    "        \n",
    "        def w(Y,t):\n",
    "            s = 1+t*Y\n",
    "            us = u(s)\n",
    "            vs = v(s)\n",
    "            return us*vs-1\n",
    "        \n",
    "        def jac_w(Y,t):\n",
    "            s = 1+t*Y\n",
    "            us = u(s)\n",
    "            vs = v(s)\n",
    "            jac_us = (1/t)*(1-vs)\n",
    "            jac_vs = (1/t)*(-vs+np.mean(1/s**2))\n",
    "            return us*jac_vs+vs*jac_us\n",
    "            \n",
    "    \n",
    "        Ym = self.peaks.min()\n",
    "        YM = self.peaks.max()\n",
    "        Ymean = self.peaks.mean()\n",
    "        \n",
    "        \n",
    "        a = -1/YM\n",
    "        if abs(a)<2*epsilon:\n",
    "            epsilon = abs(a)/n_points\n",
    "        \n",
    "        a = a + epsilon\n",
    "        b = 2*(Ymean-Ym)/(Ymean*Ym)\n",
    "        c = 2*(Ymean-Ym)/(Ym**2)\n",
    "    \n",
    "        # We look for possible roots\n",
    "        left_zeros = SPOT._rootsFinder(lambda t: w(self.peaks,t),\n",
    "                                 lambda t: jac_w(self.peaks,t),\n",
    "                                 (a+epsilon,-epsilon),\n",
    "                                 n_points,'regular')\n",
    "        \n",
    "        right_zeros = SPOT._rootsFinder(lambda t: w(self.peaks,t),\n",
    "                                  lambda t: jac_w(self.peaks,t),\n",
    "                                  (b,c),\n",
    "                                  n_points,'regular')\n",
    "    \n",
    "        # all the possible roots\n",
    "        zeros = np.concatenate((left_zeros,right_zeros))\n",
    "        \n",
    "        # 0 is always a solution so we initialize with it\n",
    "        gamma_best = 0\n",
    "        sigma_best = Ymean\n",
    "        ll_best = SPOT._log_likelihood(self.peaks,gamma_best,sigma_best)\n",
    "        \n",
    "        # we look for better candidates\n",
    "        for z in zeros:\n",
    "            gamma = u(1+z*self.peaks)-1\n",
    "            sigma = gamma/z\n",
    "            ll = SPOT._log_likelihood(self.peaks,gamma,sigma)\n",
    "            if ll>ll_best:\n",
    "                gamma_best = gamma\n",
    "                sigma_best = sigma\n",
    "                ll_best = ll\n",
    "    \n",
    "        return gamma_best,sigma_best,ll_best\n",
    "\n",
    "    \n",
    "\n",
    "    def _quantile(self,gamma,sigma):\n",
    "        \"\"\"\n",
    "        Compute the quantile at level 1-q\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        gamma : float\n",
    "\t\t    GPD parameter\n",
    "        sigma : float\n",
    "            GPD parameter\n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            quantile at level 1-q for the GPD(γ,σ,μ=0)\n",
    "        \"\"\"\n",
    "        r = self.n * self.proba / self.Nt\n",
    "        if gamma != 0:\n",
    "            return self.init_threshold + (sigma/gamma)*(pow(r,-gamma)-1)\n",
    "        else:\n",
    "            return self.init_threshold - sigma*log(r)\n",
    "\n",
    "        \n",
    "    def run(self, with_alarm = True):\n",
    "        \"\"\"\n",
    "        Run SPOT on the stream\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        with_alarm : bool\n",
    "\t\t    (default = True) If False, SPOT will adapt the threshold assuming \\\n",
    "            there is no abnormal values\n",
    "        Returns\n",
    "        ----------\n",
    "        dict\n",
    "            keys : 'thresholds' and 'alarms'\n",
    "            \n",
    "            'thresholds' contains the extreme quantiles and 'alarms' contains \\\n",
    "            the indexes of the values which have triggered alarms\n",
    "            \n",
    "        \"\"\"\n",
    "        if (self.n>self.init_data.size):\n",
    "            print('Warning : the algorithm seems to have already been run, you \\\n",
    "            should initialize before running again')\n",
    "            return {}\n",
    "        \n",
    "        # list of the thresholds\n",
    "        th = []\n",
    "        alarm = []\n",
    "        # Loop over the stream\n",
    "        for i in tqdm.tqdm(range(self.data.size)):\n",
    "    \n",
    "            # If the observed value exceeds the current threshold (alarm case)\n",
    "            if self.data[i]>self.extreme_quantile:\n",
    "                # if we want to alarm, we put it in the alarm list\n",
    "                if with_alarm:\n",
    "                    alarm.append(i)\n",
    "                # otherwise we add it in the peaks\n",
    "                else:\n",
    "                    self.peaks = np.append(self.peaks,self.data[i]-self.init_threshold)\n",
    "                    self.Nt += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw()\n",
    "                    self.extreme_quantile = self._quantile(g,s)\n",
    "\n",
    "            # case where the value exceeds the initial threshold but not the alarm ones\n",
    "            elif self.data[i]>self.init_threshold:\n",
    "                    # we add it in the peaks\n",
    "                    self.peaks = np.append(self.peaks,self.data[i]-self.init_threshold)\n",
    "                    self.Nt += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw()\n",
    "                    self.extreme_quantile = self._quantile(g,s)\n",
    "            else:\n",
    "                self.n += 1\n",
    "\n",
    "                \n",
    "            th.append(self.extreme_quantile) # thresholds record\n",
    "        \n",
    "        return {'thresholds' : th, 'alarms': alarm}\n",
    "    \n",
    "\n",
    "    def plot(self,run_results,with_alarm = True):\n",
    "        \"\"\"\n",
    "        Plot the results of given by the run\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        run_results : dict\n",
    "            results given by the 'run' method\n",
    "        with_alarm : bool\n",
    "\t\t    (default = True) If True, alarms are plotted.\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            list of the plots\n",
    "            \n",
    "        \"\"\"\n",
    "        x = range(self.data.size)\n",
    "        K = run_results.keys()\n",
    "        \n",
    "        ts_fig, = plt.plot(x,self.data,color=air_force_blue)\n",
    "        fig = [ts_fig]\n",
    "        \n",
    "        if 'thresholds' in K:\n",
    "            th = run_results['thresholds']\n",
    "            th_fig, = plt.plot(x,th,color=deep_saffron,lw=2,ls='dashed')\n",
    "            fig.append(th_fig)\n",
    "        \n",
    "        if with_alarm and ('alarms' in K):\n",
    "            alarm = run_results['alarms']\n",
    "            al_fig = plt.scatter(alarm,self.data[alarm],color='red')\n",
    "            fig.append(al_fig)\n",
    "            \n",
    "        plt.xlim((0,self.data.size))\n",
    "\n",
    "        \n",
    "        return fig\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "============================ UPPER & LOWER BOUNDS =============================\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class biSPOT:\n",
    "    \"\"\"\n",
    "    This class allows to run biSPOT algorithm on univariate dataset (upper and lower bounds)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    proba : float\n",
    "        Detection level (risk), chosen by the user\n",
    "        \n",
    "    extreme_quantile : float\n",
    "        current threshold (bound between normal and abnormal events)\n",
    "        \n",
    "    data : numpy.array\n",
    "        stream\n",
    "    \n",
    "    init_data : numpy.array\n",
    "        initial batch of observations (for the calibration/initialization step)\n",
    "    \n",
    "    init_threshold : float\n",
    "        initial threshold computed during the calibration step\n",
    "    \n",
    "    peaks : numpy.array\n",
    "        array of peaks (excesses above the initial threshold)\n",
    "    \n",
    "    n : int\n",
    "        number of observed values\n",
    "    \n",
    "    Nt : int\n",
    "        number of observed peaks\n",
    "    \"\"\"\n",
    "    def __init__(self, q = 1e-4):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\t    Parameters\n",
    "\t    ----------\n",
    "\t    q\n",
    "\t\t    Detection level (risk)\n",
    "\t\n",
    "\t    Returns\n",
    "\t    ----------\n",
    "        biSPOT object\n",
    "        \"\"\"\n",
    "        self.proba = q\n",
    "        self.data = None\n",
    "        self.init_data = None\n",
    "        self.n = 0\n",
    "        nonedict =  {'up':None,'down':None}\n",
    "        \n",
    "        self.extreme_quantile = dict.copy(nonedict)\n",
    "        self.init_threshold = dict.copy(nonedict)\n",
    "        self.peaks = dict.copy(nonedict)\n",
    "        self.gamma = dict.copy(nonedict)\n",
    "        self.sigma = dict.copy(nonedict)\n",
    "        self.Nt = {'up':0,'down':0}\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        s = ''\n",
    "        s += 'Streaming Peaks-Over-Threshold Object\\n'\n",
    "        s += 'Detection level q = %s\\n' % self.proba\n",
    "        if self.data is not None:\n",
    "            s += 'Data imported : Yes\\n'\n",
    "            s += '\\t initialization  : %s values\\n' % self.init_data.size\n",
    "            s += '\\t stream : %s values\\n' % self.data.size\n",
    "        else:\n",
    "            s += 'Data imported : No\\n'\n",
    "            return s\n",
    "            \n",
    "        if self.n == 0:\n",
    "            s += 'Algorithm initialized : No\\n'\n",
    "        else:\n",
    "            s += 'Algorithm initialized : Yes\\n'\n",
    "            s += '\\t initial threshold : %s\\n' % self.init_threshold\n",
    "            \n",
    "            r = self.n-self.init_data.size\n",
    "            if r > 0:\n",
    "                s += 'Algorithm run : Yes\\n'\n",
    "                s += '\\t number of observations : %s (%.2f %%)\\n' % (r,100*r/self.n)\n",
    "                s += '\\t triggered alarms : %s (%.2f %%)\\n' % (len(self.alarm),100*len(self.alarm)/self.n)\n",
    "            else:\n",
    "                s += '\\t number of peaks  : %s\\n' % self.Nt\n",
    "                s += '\\t upper extreme quantile : %s\\n' % self.extreme_quantile['up']\n",
    "                s += '\\t lower extreme quantile : %s\\n' % self.extreme_quantile['down']\n",
    "                s += 'Algorithm run : No\\n'\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    def fit(self,init_data,data):\n",
    "        \"\"\"\n",
    "        Import data to biSPOT object\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    init_data : list, numpy.array or pandas.Series\n",
    "\t\t    initial batch to calibrate the algorithm ()\n",
    "            \n",
    "        data : numpy.array\n",
    "\t\t    data for the run (list, np.array or pd.series)\n",
    "\t\n",
    "        \"\"\"\n",
    "        if isinstance(data,list):\n",
    "            self.data = np.array(data)\n",
    "        elif isinstance(data,np.ndarray):\n",
    "            self.data = data\n",
    "        elif isinstance(data,pd.Series):\n",
    "            self.data = data.values\n",
    "        else:\n",
    "            print('This data format (%s) is not supported' % type(data))\n",
    "            return\n",
    "            \n",
    "        if isinstance(init_data,list):\n",
    "            self.init_data = np.array(init_data)\n",
    "        elif isinstance(init_data,np.ndarray):\n",
    "            self.init_data = init_data\n",
    "        elif isinstance(init_data,pd.Series):\n",
    "            self.init_data = init_data.values\n",
    "        elif isinstance(init_data,int):\n",
    "            self.init_data = self.data[:init_data]\n",
    "            self.data = self.data[init_data:]\n",
    "        elif isinstance(init_data,float) & (init_data<1) & (init_data>0):\n",
    "            r = int(init_data*data.size)\n",
    "            self.init_data = self.data[:r]\n",
    "            self.data = self.data[r:]\n",
    "        else:\n",
    "            print('The initial data cannot be set')\n",
    "            return\n",
    "        \n",
    "    def add(self,data):\n",
    "        \"\"\"\n",
    "        This function allows to append data to the already fitted data\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    data : list, numpy.array, pandas.Series\n",
    "\t\t    data to append\n",
    "        \"\"\"\n",
    "        if isinstance(data,list):\n",
    "            data = np.array(data)\n",
    "        elif isinstance(data,np.ndarray):\n",
    "            data = data\n",
    "        elif isinstance(data,pd.Series):\n",
    "            data = data.values\n",
    "        else:\n",
    "            print('This data format (%s) is not supported' % type(data))\n",
    "            return\n",
    "        \n",
    "        self.data = np.append(self.data,data)\n",
    "        return\n",
    "\n",
    "    def initialize(self, verbose = True):\n",
    "        \"\"\"\n",
    "        Run the calibration (initialization) step\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    verbose : bool\n",
    "\t\t    (default = True) If True, gives details about the batch initialization\n",
    "        \"\"\"\n",
    "        n_init = self.init_data.size\n",
    "        \n",
    "        S = np.sort(self.init_data)     # we sort X to get the empirical quantile\n",
    "        self.init_threshold['up'] = S[int(0.98*n_init)] # t is fixed for the whole algorithm\n",
    "        self.init_threshold['down'] = S[int(0.02*n_init)] # t is fixed for the whole algorithm\n",
    "\n",
    "        # initial peaks\n",
    "        self.peaks['up'] = self.init_data[self.init_data>self.init_threshold['up']]-self.init_threshold['up']\n",
    "        self.peaks['down'] = -(self.init_data[self.init_data<self.init_threshold['down']]-self.init_threshold['down'])\n",
    "        self.Nt['up'] = self.peaks['up'].size\n",
    "        self.Nt['down'] = self.peaks['down'].size\n",
    "        self.n = n_init\n",
    "        \n",
    "        if verbose:\n",
    "            print('Initial threshold : %s' % self.init_threshold)\n",
    "            print('Number of peaks : %s' % self.Nt)\n",
    "            print('Grimshaw maximum log-likelihood estimation ... ', end = '')\n",
    "            \n",
    "        l = {'up':None,'down':None}\n",
    "        for side in ['up','down']:\n",
    "            g,s,l[side] = self._grimshaw(side)\n",
    "            self.extreme_quantile[side] = self._quantile(side,g,s)\n",
    "            self.gamma[side] = g\n",
    "            self.sigma[side] = s\n",
    "        \n",
    "        ltab = 20\n",
    "        form = ('\\t'+'%20s' + '%20.2f' + '%20.2f')\n",
    "        if verbose:\n",
    "            print('[done]')\n",
    "            print('\\t' + 'Parameters'.rjust(ltab) + 'Upper'.rjust(ltab) + 'Lower'.rjust(ltab))\n",
    "            print('\\t' + '-'*ltab*3)\n",
    "            print(form % (chr(0x03B3),self.gamma['up'],self.gamma['down']))\n",
    "            print(form % (chr(0x03C3),self.sigma['up'],self.sigma['down']))\n",
    "            print(form % ('likelihood',l['up'],l['down']))\n",
    "            print(form % ('Extreme quantile',self.extreme_quantile['up'],self.extreme_quantile['down']))\n",
    "            print('\\t' + '-'*ltab*3)\n",
    "        return \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _rootsFinder(fun,jac,bounds,npoints,method):\n",
    "        \"\"\"\n",
    "        Find possible roots of a scalar function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fun : function\n",
    "\t\t    scalar function \n",
    "        jac : function\n",
    "            first order derivative of the function  \n",
    "        bounds : tuple\n",
    "            (min,max) interval for the roots search    \n",
    "        npoints : int\n",
    "            maximum number of roots to output      \n",
    "        method : str\n",
    "            'regular' : regular sample of the search interval, 'random' : uniform (distribution) sample of the search interval\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        numpy.array\n",
    "            possible roots of the function\n",
    "        \"\"\"\n",
    "        if method == 'regular':\n",
    "            step = (bounds[1]-bounds[0])/(npoints+1)\n",
    "            X0 = np.arange(bounds[0]+step,bounds[1],step)\n",
    "        elif method == 'random':\n",
    "            X0 = np.random.uniform(bounds[0],bounds[1],npoints)\n",
    "        \n",
    "        def objFun(X,f,jac):\n",
    "            g = 0\n",
    "            j = np.zeros(X.shape)\n",
    "            i = 0\n",
    "            for x in X:\n",
    "                fx = f(x)\n",
    "                g = g+fx**2\n",
    "                j[i] = 2*fx*jac(x)\n",
    "                i = i+1\n",
    "            return g,j\n",
    "        opt = minimize(lambda X:objFun(X,fun,jac), X0, \n",
    "                       method='L-BFGS-B', \n",
    "                       jac=True, bounds=[bounds]*len(X0))\n",
    "        \n",
    "        X = opt.x\n",
    "        np.round(X,decimals = 5)\n",
    "        return np.unique(X)\n",
    "    \n",
    "    \n",
    "    def _log_likelihood(Y,gamma,sigma):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood for the Generalized Pareto Distribution (μ=0)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Y : numpy.array\n",
    "\t\t    observations\n",
    "        gamma : float\n",
    "            GPD index parameter\n",
    "        sigma : float\n",
    "            GPD scale parameter (>0)   \n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            log-likelihood of the sample Y to be drawn from a GPD(γ,σ,μ=0)\n",
    "        \"\"\"\n",
    "        n = Y.size\n",
    "        if gamma != 0:\n",
    "            tau = gamma/sigma\n",
    "            L = -n * log(sigma) - ( 1 + (1/gamma) ) * ( np.log(1+tau*Y) ).sum()\n",
    "        else:\n",
    "            L = n * ( 1 + log(Y.mean()) )\n",
    "        return L\n",
    "\n",
    "\n",
    "    def _grimshaw(self,side,epsilon = 1e-8, n_points = 10):\n",
    "        \"\"\"\n",
    "        Compute the GPD parameters estimation with the Grimshaw's trick\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        epsilon : float\n",
    "\t\t    numerical parameter to perform (default : 1e-8)\n",
    "        n_points : int\n",
    "            maximum number of candidates for maximum likelihood (default : 10)\n",
    "        Returns\n",
    "        ----------\n",
    "        gamma_best,sigma_best,ll_best\n",
    "            gamma estimates, sigma estimates and corresponding log-likelihood\n",
    "        \"\"\"\n",
    "        def u(s):\n",
    "            return 1 + np.log(s).mean()\n",
    "            \n",
    "        def v(s):\n",
    "            return np.mean(1/s)\n",
    "        \n",
    "        def w(Y,t):\n",
    "            s = 1+t*Y\n",
    "            us = u(s)\n",
    "            vs = v(s)\n",
    "            return us*vs-1\n",
    "        \n",
    "        def jac_w(Y,t):\n",
    "            s = 1+t*Y\n",
    "            us = u(s)\n",
    "            vs = v(s)\n",
    "            jac_us = (1/t)*(1-vs)\n",
    "            jac_vs = (1/t)*(-vs+np.mean(1/s**2))\n",
    "            return us*jac_vs+vs*jac_us\n",
    "            \n",
    "    \n",
    "        Ym = self.peaks[side].min()\n",
    "        YM = self.peaks[side].max()\n",
    "        Ymean = self.peaks[side].mean()\n",
    "        \n",
    "        \n",
    "        a = -1/YM\n",
    "        if abs(a)<2*epsilon:\n",
    "            epsilon = abs(a)/n_points\n",
    "        \n",
    "        a = a + epsilon\n",
    "        b = 2*(Ymean-Ym)/(Ymean*Ym)\n",
    "        c = 2*(Ymean-Ym)/(Ym**2)\n",
    "    \n",
    "        # We look for possible roots\n",
    "        left_zeros = biSPOT._rootsFinder(lambda t: w(self.peaks[side],t),\n",
    "                                 lambda t: jac_w(self.peaks[side],t),\n",
    "                                 (a+epsilon,-epsilon),\n",
    "                                 n_points,'regular')\n",
    "        \n",
    "        right_zeros = biSPOT._rootsFinder(lambda t: w(self.peaks[side],t),\n",
    "                                  lambda t: jac_w(self.peaks[side],t),\n",
    "                                  (b,c),\n",
    "                                  n_points,'regular')\n",
    "    \n",
    "        # all the possible roots\n",
    "        zeros = np.concatenate((left_zeros,right_zeros))\n",
    "        \n",
    "        # 0 is always a solution so we initialize with it\n",
    "        gamma_best = 0\n",
    "        sigma_best = Ymean\n",
    "        ll_best = biSPOT._log_likelihood(self.peaks[side],gamma_best,sigma_best)\n",
    "        \n",
    "        # we look for better candidates\n",
    "        for z in zeros:\n",
    "            gamma = u(1+z*self.peaks[side])-1\n",
    "            sigma = gamma/z\n",
    "            ll = biSPOT._log_likelihood(self.peaks[side],gamma,sigma)\n",
    "            if ll>ll_best:\n",
    "                gamma_best = gamma\n",
    "                sigma_best = sigma\n",
    "                ll_best = ll\n",
    "    \n",
    "        return gamma_best,sigma_best,ll_best\n",
    "\n",
    "    \n",
    "\n",
    "    def _quantile(self,side,gamma,sigma):\n",
    "        \"\"\"\n",
    "        Compute the quantile at level 1-q for a given side\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        side : str\n",
    "            'up' or 'down'\n",
    "        gamma : float\n",
    "\t\t    GPD parameter\n",
    "        sigma : float\n",
    "            GPD parameter\n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            quantile at level 1-q for the GPD(γ,σ,μ=0)\n",
    "        \"\"\"\n",
    "        if side == 'up':\n",
    "            r = self.n * self.proba / self.Nt[side]\n",
    "            if gamma != 0:\n",
    "                return self.init_threshold['up'] + (sigma/gamma)*(pow(r,-gamma)-1)\n",
    "            else:\n",
    "                return self.init_threshold['up'] - sigma*log(r)\n",
    "        elif side == 'down':\n",
    "            r = self.n * self.proba / self.Nt[side]\n",
    "            if gamma != 0:\n",
    "                return self.init_threshold['down'] - (sigma/gamma)*(pow(r,-gamma)-1)\n",
    "            else:\n",
    "                return self.init_threshold['down'] + sigma*log(r)\n",
    "        else:\n",
    "            print('error : the side is not right')\n",
    "\n",
    "        \n",
    "    def run(self, with_alarm = True):\n",
    "        \"\"\"\n",
    "        Run biSPOT on the stream\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        with_alarm : bool\n",
    "\t\t    (default = True) If False, SPOT will adapt the threshold assuming \\\n",
    "            there is no abnormal values\n",
    "        Returns\n",
    "        ----------\n",
    "        dict\n",
    "            keys : 'upper_thresholds', 'lower_thresholds' and 'alarms'\n",
    "            \n",
    "            '***-thresholds' contains the extreme quantiles and 'alarms' contains \\\n",
    "            the indexes of the values which have triggered alarms\n",
    "            \n",
    "        \"\"\"\n",
    "        if (self.n>self.init_data.size):\n",
    "            print('Warning : the algorithm seems to have already been run, you \\\n",
    "            should initialize before running again')\n",
    "            return {}\n",
    "        \n",
    "        # list of the thresholds\n",
    "        thup = []\n",
    "        thdown = []\n",
    "        alarm = []\n",
    "        # Loop over the stream\n",
    "        for i in tqdm.tqdm(range(self.data.size)):\n",
    "    \n",
    "            # If the observed value exceeds the current threshold (alarm case)\n",
    "            if self.data[i]>self.extreme_quantile['up'] :\n",
    "                # if we want to alarm, we put it in the alarm list\n",
    "                if with_alarm:\n",
    "                    alarm.append(i)\n",
    "                # otherwise we add it in the peaks\n",
    "                else:\n",
    "                    self.peaks['up'] = np.append(self.peaks['up'],self.data[i]-self.init_threshold['up'])\n",
    "                    self.Nt['up'] += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw('up')\n",
    "                    self.extreme_quantile['up'] = self._quantile('up',g,s)\n",
    "\n",
    "            # case where the value exceeds the initial threshold but not the alarm ones\n",
    "            elif self.data[i]>self.init_threshold['up']:\n",
    "                    # we add it in the peaks\n",
    "                    self.peaks['up'] = np.append(self.peaks['up'],self.data[i]-self.init_threshold['up'])\n",
    "                    self.Nt['up'] += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw('up')\n",
    "                    self.extreme_quantile['up'] = self._quantile('up',g,s)\n",
    "                    \n",
    "            elif self.data[i]<self.extreme_quantile['down'] :\n",
    "                # if we want to alarm, we put it in the alarm list\n",
    "                if with_alarm:\n",
    "                    alarm.append(i)\n",
    "                # otherwise we add it in the peaks\n",
    "                else:\n",
    "                    self.peaks['down'] = np.append(self.peaks['down'],-(self.data[i]-self.init_threshold['down']))\n",
    "                    self.Nt['down'] += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw('down')\n",
    "                    self.extreme_quantile['down'] = self._quantile('down',g,s)\n",
    "\n",
    "            # case where the value exceeds the initial threshold but not the alarm ones\n",
    "            elif self.data[i]<self.init_threshold['down']:\n",
    "                    # we add it in the peaks\n",
    "                    self.peaks['down'] = np.append(self.peaks['down'],-(self.data[i]-self.init_threshold['down']))\n",
    "                    self.Nt['down'] += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw('down')\n",
    "                    self.extreme_quantile['down'] = self._quantile('down',g,s)\n",
    "            else:\n",
    "                self.n += 1\n",
    "\n",
    "                \n",
    "            thup.append(self.extreme_quantile['up']) # thresholds record\n",
    "            thdown.append(self.extreme_quantile['down']) # thresholds record\n",
    "        \n",
    "        return {'upper_thresholds' : thup,'lower_thresholds' : thdown, 'alarms': alarm}\n",
    "    \n",
    "    def plot(self,run_results,with_alarm = True):\n",
    "        \"\"\"\n",
    "        Plot the results of given by the run\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        run_results : dict\n",
    "            results given by the 'run' method\n",
    "        with_alarm : bool\n",
    "\t\t    (default = True) If True, alarms are plotted.\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            list of the plots\n",
    "            \n",
    "        \"\"\"\n",
    "        x = range(self.data.size)\n",
    "        K = run_results.keys()\n",
    "        \n",
    "        ts_fig, = plt.plot(x,self.data,color=air_force_blue)\n",
    "        fig = [ts_fig]\n",
    "        \n",
    "        if 'upper_thresholds' in K:\n",
    "            thup = run_results['upper_thresholds']\n",
    "            uth_fig, = plt.plot(x,thup,color=deep_saffron,lw=2,ls='dashed')\n",
    "            fig.append(uth_fig)\n",
    "            \n",
    "        if 'lower_thresholds' in K:\n",
    "            thdown = run_results['lower_thresholds']\n",
    "            lth_fig, = plt.plot(x,thdown,color=deep_saffron,lw=2,ls='dashed')\n",
    "            fig.append(lth_fig)\n",
    "        \n",
    "        if with_alarm and ('alarms' in K):\n",
    "            alarm = run_results['alarms']\n",
    "            al_fig = plt.scatter(alarm,self.data[alarm],color='red')\n",
    "            fig.append(al_fig)\n",
    "            \n",
    "        plt.xlim((0,self.data.size))\n",
    "\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "================================= WITH DRIFT ==================================\n",
    "\"\"\"\n",
    "\n",
    "def backMean(X,d):\n",
    "    M = []\n",
    "    w = X[:d].sum()\n",
    "    M.append(w/d)\n",
    "    for i in range(d,len(X)):\n",
    "        w = w - X[i-d] + X[i]\n",
    "        M.append(w/d)\n",
    "    return np.array(M)\n",
    "\n",
    "\n",
    "\n",
    "class dSPOT:\n",
    "    \"\"\"\n",
    "    This class allows to run DSPOT algorithm on univariate dataset (upper-bound)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    proba : float\n",
    "        Detection level (risk), chosen by the user\n",
    "        \n",
    "    depth : int\n",
    "        Number of observations to compute the moving average\n",
    "        \n",
    "    extreme_quantile : float\n",
    "        current threshold (bound between normal and abnormal events)\n",
    "        \n",
    "    data : numpy.array\n",
    "        stream\n",
    "    \n",
    "    init_data : numpy.array\n",
    "        initial batch of observations (for the calibration/initialization step)\n",
    "    \n",
    "    init_threshold : float\n",
    "        initial threshold computed during the calibration step\n",
    "    \n",
    "    peaks : numpy.array\n",
    "        array of peaks (excesses above the initial threshold)\n",
    "    \n",
    "    n : int\n",
    "        number of observed values\n",
    "    \n",
    "    Nt : int\n",
    "        number of observed peaks\n",
    "    \"\"\"\n",
    "    def __init__(self, q, depth):\n",
    "        self.proba = q\n",
    "        self.extreme_quantile = None\n",
    "        self.data = None\n",
    "        self.init_data = None\n",
    "        self.init_threshold = None\n",
    "        self.peaks = None\n",
    "        self.n = 0\n",
    "        self.Nt = 0\n",
    "        self.depth = depth\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = ''\n",
    "        s += 'Streaming Peaks-Over-Threshold Object\\n'\n",
    "        s += 'Detection level q = %s\\n' % self.proba\n",
    "        if self.data is not None:\n",
    "            s += 'Data imported : Yes\\n'\n",
    "            s += '\\t initialization  : %s values\\n' % self.init_data.size\n",
    "            s += '\\t stream : %s values\\n' % self.data.size\n",
    "        else:\n",
    "            s += 'Data imported : No\\n'\n",
    "            return s\n",
    "            \n",
    "        if self.n == 0:\n",
    "            s += 'Algorithm initialized : No\\n'\n",
    "        else:\n",
    "            s += 'Algorithm initialized : Yes\\n'\n",
    "            s += '\\t initial threshold : %s\\n' % self.init_threshold\n",
    "            \n",
    "            r = self.n-self.init_data.size\n",
    "            if r > 0:\n",
    "                s += 'Algorithm run : Yes\\n'\n",
    "                s += '\\t number of observations : %s (%.2f %%)\\n' % (r,100*r/self.n)\n",
    "                s += '\\t triggered alarms : %s (%.2f %%)\\n' % (len(self.alarm),100*len(self.alarm)/self.n)\n",
    "            else:\n",
    "                s += '\\t number of peaks  : %s\\n' % self.Nt\n",
    "                s += '\\t extreme quantile : %s\\n' % self.extreme_quantile\n",
    "                s += 'Algorithm run : No\\n'\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    def fit(self,init_data,data):\n",
    "        \"\"\"\n",
    "        Import data to DSPOT object\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    init_data : list, numpy.array or pandas.Series\n",
    "\t\t    initial batch to calibrate the algorithm\n",
    "            \n",
    "        data : numpy.array\n",
    "\t\t    data for the run (list, np.array or pd.series)\n",
    "\t\n",
    "        \"\"\"\n",
    "        if isinstance(data,list):\n",
    "            self.data = np.array(data)\n",
    "        elif isinstance(data,np.ndarray):\n",
    "            self.data = data\n",
    "        elif isinstance(data,pd.Series):\n",
    "            self.data = data.values\n",
    "        else:\n",
    "            print('This data format (%s) is not supported' % type(data))\n",
    "            return\n",
    "            \n",
    "        if isinstance(init_data,list):\n",
    "            self.init_data = np.array(init_data)\n",
    "        elif isinstance(init_data,np.ndarray):\n",
    "            self.init_data = init_data\n",
    "        elif isinstance(init_data,pd.Series):\n",
    "            self.init_data = init_data.values\n",
    "        elif isinstance(init_data,int):\n",
    "            self.init_data = self.data[:init_data]\n",
    "            self.data = self.data[init_data:]\n",
    "        elif isinstance(init_data,float) & (init_data<1) & (init_data>0):\n",
    "            r = int(init_data*data.size)\n",
    "            self.init_data = self.data[:r]\n",
    "            self.data = self.data[r:]\n",
    "        else:\n",
    "            print('The initial data cannot be set')\n",
    "            return\n",
    "        \n",
    "    def add(self,data):\n",
    "        \"\"\"\n",
    "        This function allows to append data to the already fitted data\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    data : list, numpy.array, pandas.Series\n",
    "\t\t    data to append\n",
    "        \"\"\"\n",
    "        if isinstance(data,list):\n",
    "            data = np.array(data)\n",
    "        elif isinstance(data,np.ndarray):\n",
    "            data = data\n",
    "        elif isinstance(data,pd.Series):\n",
    "            data = data.values\n",
    "        else:\n",
    "            print('This data format (%s) is not supported' % type(data))\n",
    "            return\n",
    "        \n",
    "        self.data = np.append(self.data,data)\n",
    "        return\n",
    "    \n",
    "    def initialize(self, verbose = True):\n",
    "        \"\"\"\n",
    "        Run the calibration (initialization) step\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    verbose : bool\n",
    "\t\t    (default = True) If True, gives details about the batch initialization\n",
    "        \"\"\"\n",
    "        n_init = self.init_data.size - self.depth\n",
    "        \n",
    "        M = backMean(self.init_data,self.depth)\n",
    "        T = self.init_data[self.depth:]-M[:-1] # new variable\n",
    "        \n",
    "        S = np.sort(T)     # we sort X to get the empirical quantile\n",
    "        self.init_threshold = S[int(0.98*n_init)] # t is fixed for the whole algorithm\n",
    "\n",
    "        # initial peaks\n",
    "        self.peaks = T[T>self.init_threshold]-self.init_threshold \n",
    "        self.Nt = self.peaks.size\n",
    "        self.n = n_init\n",
    "        \n",
    "        if verbose:\n",
    "            print('Initial threshold : %s' % self.init_threshold)\n",
    "            print('Number of peaks : %s' % self.Nt)\n",
    "            print('Grimshaw maximum log-likelihood estimation ... ', end = '')\n",
    "            \n",
    "        g,s,l = self._grimshaw()\n",
    "        self.extreme_quantile = self._quantile(g,s)\n",
    "        \n",
    "        if verbose:\n",
    "            print('[done]')\n",
    "            print('\\t'+chr(0x03B3) + ' = ' + str(g))\n",
    "            print('\\t'+chr(0x03C3) + ' = ' + str(s))\n",
    "            print('\\tL = ' + str(l))\n",
    "            print('Extreme quantile (probability = %s): %s' % (self.proba,self.extreme_quantile))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _rootsFinder(fun,jac,bounds,npoints,method):\n",
    "        \"\"\"\n",
    "        Find possible roots of a scalar function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fun : function\n",
    "\t\t    scalar function \n",
    "        jac : function\n",
    "            first order derivative of the function  \n",
    "        bounds : tuple\n",
    "            (min,max) interval for the roots search    \n",
    "        npoints : int\n",
    "            maximum number of roots to output      \n",
    "        method : str\n",
    "            'regular' : regular sample of the search interval, 'random' : uniform (distribution) sample of the search interval\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        numpy.array\n",
    "            possible roots of the function\n",
    "        \"\"\"\n",
    "        if method == 'regular':\n",
    "            step = (bounds[1]-bounds[0])/(npoints+1)\n",
    "            X0 = np.arange(bounds[0]+step,bounds[1],step)\n",
    "        elif method == 'random':\n",
    "            X0 = np.random.uniform(bounds[0],bounds[1],npoints)\n",
    "        \n",
    "        def objFun(X,f,jac):\n",
    "            g = 0\n",
    "            j = np.zeros(X.shape)\n",
    "            i = 0\n",
    "            for x in X:\n",
    "                fx = f(x)\n",
    "                g = g+fx**2\n",
    "                j[i] = 2*fx*jac(x)\n",
    "                i = i+1\n",
    "            return g,j\n",
    "        \n",
    "        opt = minimize(lambda X:objFun(X,fun,jac), X0, \n",
    "                       method='L-BFGS-B', \n",
    "                       jac=True, bounds=[bounds]*len(X0))\n",
    "        \n",
    "        X = opt.x\n",
    "        np.round(X,decimals = 5)\n",
    "        return np.unique(X)\n",
    "    \n",
    "    \n",
    "    def _log_likelihood(Y,gamma,sigma):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood for the Generalized Pareto Distribution (μ=0)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Y : numpy.array\n",
    "\t\t    observations\n",
    "        gamma : float\n",
    "            GPD index parameter\n",
    "        sigma : float\n",
    "            GPD scale parameter (>0)   \n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            log-likelihood of the sample Y to be drawn from a GPD(γ,σ,μ=0)\n",
    "        \"\"\"\n",
    "        n = Y.size\n",
    "        if gamma != 0:\n",
    "            tau = gamma/sigma\n",
    "            L = -n * log(sigma) - ( 1 + (1/gamma) ) * ( np.log(1+tau*Y) ).sum()\n",
    "        else:\n",
    "            L = n * ( 1 + log(Y.mean()) )\n",
    "        return L\n",
    "\n",
    "\n",
    "    def _grimshaw(self,epsilon = 1e-8, n_points = 10):\n",
    "        \"\"\"\n",
    "        Compute the GPD parameters estimation with the Grimshaw's trick\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        epsilon : float\n",
    "\t\t    numerical parameter to perform (default : 1e-8)\n",
    "        n_points : int\n",
    "            maximum number of candidates for maximum likelihood (default : 10)\n",
    "        Returns\n",
    "        ----------\n",
    "        gamma_best,sigma_best,ll_best\n",
    "            gamma estimates, sigma estimates and corresponding log-likelihood\n",
    "        \"\"\"\n",
    "        def u(s):\n",
    "            return 1 + np.log(s).mean()\n",
    "            \n",
    "        def v(s):\n",
    "            return np.mean(1/s)\n",
    "        \n",
    "        def w(Y,t):\n",
    "            s = 1+t*Y\n",
    "            us = u(s)\n",
    "            vs = v(s)\n",
    "            return us*vs-1\n",
    "        \n",
    "        def jac_w(Y,t):\n",
    "            s = 1+t*Y\n",
    "            us = u(s)\n",
    "            vs = v(s)\n",
    "            jac_us = (1/t)*(1-vs)\n",
    "            jac_vs = (1/t)*(-vs+np.mean(1/s**2))\n",
    "            return us*jac_vs+vs*jac_us\n",
    "            \n",
    "    \n",
    "        Ym = self.peaks.min()\n",
    "        YM = self.peaks.max()\n",
    "        Ymean = self.peaks.mean()\n",
    "        \n",
    "        \n",
    "        a = -1/YM\n",
    "        if abs(a)<2*epsilon:\n",
    "            epsilon = abs(a)/n_points\n",
    "        \n",
    "        a = a + epsilon\n",
    "        b = 2*(Ymean-Ym)/(Ymean*Ym)\n",
    "        c = 2*(Ymean-Ym)/(Ym**2)\n",
    "    \n",
    "        # We look for possible roots\n",
    "        left_zeros = SPOT._rootsFinder(lambda t: w(self.peaks,t),\n",
    "                                 lambda t: jac_w(self.peaks,t),\n",
    "                                 (a+epsilon,-epsilon),\n",
    "                                 n_points,'regular')\n",
    "        \n",
    "        right_zeros = SPOT._rootsFinder(lambda t: w(self.peaks,t),\n",
    "                                  lambda t: jac_w(self.peaks,t),\n",
    "                                  (b,c),\n",
    "                                  n_points,'regular')\n",
    "    \n",
    "        # all the possible roots\n",
    "        zeros = np.concatenate((left_zeros,right_zeros))\n",
    "        \n",
    "        # 0 is always a solution so we initialize with it\n",
    "        gamma_best = 0\n",
    "        sigma_best = Ymean\n",
    "        ll_best = SPOT._log_likelihood(self.peaks,gamma_best,sigma_best)\n",
    "        \n",
    "        # we look for better candidates\n",
    "        for z in zeros:\n",
    "            gamma = u(1+z*self.peaks)-1\n",
    "            sigma = gamma/z\n",
    "            ll = dSPOT._log_likelihood(self.peaks,gamma,sigma)\n",
    "            if ll>ll_best:\n",
    "                gamma_best = gamma\n",
    "                sigma_best = sigma\n",
    "                ll_best = ll\n",
    "    \n",
    "        return gamma_best,sigma_best,ll_best\n",
    "\n",
    "    \n",
    "\n",
    "    def _quantile(self,gamma,sigma):\n",
    "        \"\"\"\n",
    "        Compute the quantile at level 1-q\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        gamma : float\n",
    "\t\t    GPD parameter\n",
    "        sigma : float\n",
    "            GPD parameter\n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            quantile at level 1-q for the GPD(γ,σ,μ=0)\n",
    "        \"\"\"\n",
    "        r = self.n * self.proba / self.Nt\n",
    "        if gamma != 0:\n",
    "            return self.init_threshold + (sigma/gamma)*(pow(r,-gamma)-1)\n",
    "        else:\n",
    "            return self.init_threshold - sigma*log(r)\n",
    "\n",
    "        \n",
    "    def run(self, with_alarm = True):\n",
    "        \"\"\"\n",
    "        Run biSPOT on the stream\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        with_alarm : bool\n",
    "\t\t    (default = True) If False, SPOT will adapt the threshold assuming \\\n",
    "            there is no abnormal values\n",
    "        Returns\n",
    "        ----------\n",
    "        dict\n",
    "            keys : 'upper_thresholds', 'lower_thresholds' and 'alarms'\n",
    "            \n",
    "            '***-thresholds' contains the extreme quantiles and 'alarms' contains \\\n",
    "            the indexes of the values which have triggered alarms\n",
    "            \n",
    "        \"\"\"\n",
    "        if (self.n>self.init_data.size):\n",
    "            print('Warning : the algorithm seems to have already been run, you \\\n",
    "            should initialize before running again')\n",
    "            return {}\n",
    "        \n",
    "        # actual normal window\n",
    "        W = self.init_data[-self.depth:]\n",
    "        \n",
    "        # list of the thresholds\n",
    "        th = []\n",
    "        alarm = []\n",
    "        # Loop over the stream\n",
    "        for i in tqdm.tqdm(range(self.data.size)):\n",
    "            Mi = W.mean()\n",
    "            # If the observed value exceeds the current threshold (alarm case)\n",
    "            if (self.data[i]-Mi)>self.extreme_quantile:\n",
    "                # if we want to alarm, we put it in the alarm list\n",
    "                if with_alarm:\n",
    "                    alarm.append(i)\n",
    "                # otherwise we add it in the peaks\n",
    "                else:\n",
    "                    self.peaks = np.append(self.peaks,self.data[i]-Mi-self.init_threshold)\n",
    "                    self.Nt += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw()\n",
    "                    self.extreme_quantile = self._quantile(g,s) #+ Mi\n",
    "                    W = np.append(W[1:],self.data[i])\n",
    "\n",
    "            # case where the value exceeds the initial threshold but not the alarm ones\n",
    "            elif (self.data[i]-Mi)>self.init_threshold:\n",
    "                    # we add it in the peaks\n",
    "                    self.peaks = np.append(self.peaks,self.data[i]-Mi-self.init_threshold)\n",
    "                    self.Nt += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw()\n",
    "                    self.extreme_quantile = self._quantile(g,s) #+ Mi\n",
    "                    W = np.append(W[1:],self.data[i])\n",
    "            else:\n",
    "                self.n += 1\n",
    "                W = np.append(W[1:],self.data[i])\n",
    "\n",
    "                \n",
    "            th.append(self.extreme_quantile+Mi) # thresholds record\n",
    "        \n",
    "        return {'thresholds' : th, 'alarms': alarm}\n",
    "    \n",
    "\n",
    "    def plot(self,run_results, with_alarm = True):\n",
    "        \"\"\"\n",
    "        Plot the results given by the run\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        run_results : dict\n",
    "            results given by the 'run' method\n",
    "        with_alarm : bool\n",
    "\t\t    (default = True) If True, alarms are plotted.\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            list of the plots\n",
    "            \n",
    "        \"\"\"\n",
    "        x = range(self.data.size)\n",
    "        K = run_results.keys()\n",
    "        \n",
    "        ts_fig, = plt.plot(x,self.data,color=air_force_blue)\n",
    "        fig = [ts_fig]\n",
    "        \n",
    "#        if 'upper_thresholds' in K:\n",
    "#            thup = run_results['upper_thresholds']\n",
    "#            uth_fig, = plt.plot(x,thup,color=deep_saffron,lw=2,ls='dashed')\n",
    "#            fig.append(uth_fig)\n",
    "#            \n",
    "#        if 'lower_thresholds' in K:\n",
    "#            thdown = run_results['lower_thresholds']\n",
    "#            lth_fig, = plt.plot(x,thdown,color=deep_saffron,lw=2,ls='dashed')\n",
    "#            fig.append(lth_fig)\n",
    "        \n",
    "        if 'thresholds' in K:\n",
    "            th = run_results['thresholds']\n",
    "            th_fig, = plt.plot(x,th,color=deep_saffron,lw=2,ls='dashed')\n",
    "            fig.append(th_fig)\n",
    "        \n",
    "        if with_alarm and ('alarms' in K):\n",
    "            alarm = run_results['alarms']\n",
    "            if len(alarm)>0:\n",
    "                plt.scatter(alarm,self.data[alarm],color='red')\n",
    "            \n",
    "        plt.xlim((0,self.data.size))\n",
    "\n",
    "        \n",
    "        return fig\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "=========================== DRIFT & DOUBLE BOUNDS =============================\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class bidSPOT:\n",
    "    \"\"\"\n",
    "    This class allows to run DSPOT algorithm on univariate dataset (upper and lower bounds)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    proba : float\n",
    "        Detection level (risk), chosen by the user\n",
    "        \n",
    "    depth : int\n",
    "        Number of observations to compute the moving average\n",
    "        \n",
    "    extreme_quantile : float\n",
    "        current threshold (bound between normal and abnormal events)\n",
    "        \n",
    "    data : numpy.array\n",
    "        stream\n",
    "    \n",
    "    init_data : numpy.array\n",
    "        initial batch of observations (for the calibration/initialization step)\n",
    "    \n",
    "    init_threshold : float\n",
    "        initial threshold computed during the calibration step\n",
    "    \n",
    "    peaks : numpy.array\n",
    "        array of peaks (excesses above the initial threshold)\n",
    "    \n",
    "    n : int\n",
    "        number of observed values\n",
    "    \n",
    "    Nt : int\n",
    "        number of observed peaks\n",
    "    \"\"\"\n",
    "    def __init__(self, q = 1e-4, depth = 10):\n",
    "        self.proba = q\n",
    "        self.data = None\n",
    "        self.init_data = None\n",
    "        self.n = 0\n",
    "        self.depth = depth\n",
    "        \n",
    "        nonedict =  {'up':None,'down':None}\n",
    "        \n",
    "        self.extreme_quantile = dict.copy(nonedict)\n",
    "        self.init_threshold = dict.copy(nonedict)\n",
    "        self.peaks = dict.copy(nonedict)\n",
    "        self.gamma = dict.copy(nonedict)\n",
    "        self.sigma = dict.copy(nonedict)\n",
    "        self.Nt = {'up':0,'down':0}\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        s = ''\n",
    "        s += 'Streaming Peaks-Over-Threshold Object\\n'\n",
    "        s += 'Detection level q = %s\\n' % self.proba\n",
    "        if self.data is not None:\n",
    "            s += 'Data imported : Yes\\n'\n",
    "            s += '\\t initialization  : %s values\\n' % self.init_data.size\n",
    "            s += '\\t stream : %s values\\n' % self.data.size\n",
    "        else:\n",
    "            s += 'Data imported : No\\n'\n",
    "            return s\n",
    "            \n",
    "        if self.n == 0:\n",
    "            s += 'Algorithm initialized : No\\n'\n",
    "        else:\n",
    "            s += 'Algorithm initialized : Yes\\n'\n",
    "            s += '\\t initial threshold : %s\\n' % self.init_threshold\n",
    "            \n",
    "            r = self.n-self.init_data.size\n",
    "            if r > 0:\n",
    "                s += 'Algorithm run : Yes\\n'\n",
    "                s += '\\t number of observations : %s (%.2f %%)\\n' % (r,100*r/self.n)\n",
    "                s += '\\t triggered alarms : %s (%.2f %%)\\n' % (len(self.alarm),100*len(self.alarm)/self.n)\n",
    "            else:\n",
    "                s += '\\t number of peaks  : %s\\n' % self.Nt\n",
    "                s += '\\t upper extreme quantile : %s\\n' % self.extreme_quantile['up']\n",
    "                s += '\\t lower extreme quantile : %s\\n' % self.extreme_quantile['down']\n",
    "                s += 'Algorithm run : No\\n'\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    def fit(self,init_data,data):\n",
    "        \"\"\"\n",
    "        Import data to biDSPOT object\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    init_data : list, numpy.array or pandas.Series\n",
    "\t\t    initial batch to calibrate the algorithm\n",
    "            \n",
    "        data : numpy.array\n",
    "\t\t    data for the run (list, np.array or pd.series)\n",
    "\t\n",
    "        \"\"\"\n",
    "        if isinstance(data,list):\n",
    "            self.data = np.array(data)\n",
    "        elif isinstance(data,np.ndarray):\n",
    "            self.data = data\n",
    "        elif isinstance(data,pd.Series):\n",
    "            self.data = data.values\n",
    "        else:\n",
    "            print('This data format (%s) is not supported' % type(data))\n",
    "            return\n",
    "            \n",
    "        if isinstance(init_data,list):\n",
    "            self.init_data = np.array(init_data)\n",
    "        elif isinstance(init_data,np.ndarray):\n",
    "            self.init_data = init_data\n",
    "        elif isinstance(init_data,pd.Series):\n",
    "            self.init_data = init_data.values\n",
    "        elif isinstance(init_data,int):\n",
    "            self.init_data = self.data[:init_data]\n",
    "            self.data = self.data[init_data:]\n",
    "        elif isinstance(init_data,float) & (init_data<1) & (init_data>0):\n",
    "            r = int(init_data*data.size)\n",
    "            self.init_data = self.data[:r]\n",
    "            self.data = self.data[r:]\n",
    "        else:\n",
    "            print('The initial data cannot be set')\n",
    "            return\n",
    "        \n",
    "    def add(self,data):\n",
    "        \"\"\"\n",
    "        This function allows to append data to the already fitted data\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    data : list, numpy.array, pandas.Series\n",
    "\t\t    data to append\n",
    "        \"\"\"\n",
    "        if isinstance(data,list):\n",
    "            data = np.array(data)\n",
    "        elif isinstance(data,np.ndarray):\n",
    "            data = data\n",
    "        elif isinstance(data,pd.Series):\n",
    "            data = data.values\n",
    "        else:\n",
    "            print('This data format (%s) is not supported' % type(data))\n",
    "            return\n",
    "        \n",
    "        self.data = np.append(self.data,data)\n",
    "        return\n",
    "    \n",
    "    def initialize(self, verbose = True):\n",
    "        \"\"\"\n",
    "        Run the calibration (initialization) step\n",
    "        \n",
    "        Parameters\n",
    "\t    ----------\n",
    "\t    verbose : bool\n",
    "\t\t    (default = True) If True, gives details about the batch initialization\n",
    "        \"\"\"\n",
    "        n_init = self.init_data.size - self.depth\n",
    "        \n",
    "        M = backMean(self.init_data,self.depth)\n",
    "        T = self.init_data[self.depth:]-M[:-1] # new variable\n",
    "        \n",
    "        S = np.sort(T)     # we sort T to get the empirical quantile\n",
    "        self.init_threshold['up'] = S[int(0.98*n_init)] # t is fixed for the whole algorithm\n",
    "        self.init_threshold['down'] = S[int(0.02*n_init)] # t is fixed for the whole algorithm\n",
    "\n",
    "        # initial peaks\n",
    "        self.peaks['up'] = T[T>self.init_threshold['up']]-self.init_threshold['up']\n",
    "        self.peaks['down'] = -( T[ T<self.init_threshold['down'] ] - self.init_threshold['down'] )\n",
    "        self.Nt['up'] = self.peaks['up'].size\n",
    "        self.Nt['down'] = self.peaks['down'].size\n",
    "        self.n = n_init\n",
    "        \n",
    "        if verbose:\n",
    "            print('Initial threshold : %s' % self.init_threshold)\n",
    "            print('Number of peaks : %s' % self.Nt)\n",
    "            print('Grimshaw maximum log-likelihood estimation ... ', end = '')\n",
    "            \n",
    "        l = {'up':None,'down':None}\n",
    "        for side in ['up','down']:\n",
    "            g,s,l[side] = self._grimshaw(side)\n",
    "            self.extreme_quantile[side] = self._quantile(side,g,s)\n",
    "            self.gamma[side] = g\n",
    "            self.sigma[side] = s\n",
    "        \n",
    "        ltab = 20\n",
    "        form = ('\\t'+'%20s' + '%20.2f' + '%20.2f')\n",
    "        if verbose:\n",
    "            print('[done]')\n",
    "            print('\\t' + 'Parameters'.rjust(ltab) + 'Upper'.rjust(ltab) + 'Lower'.rjust(ltab))\n",
    "            print('\\t' + '-'*ltab*3)\n",
    "            print(form % (chr(0x03B3),self.gamma['up'],self.gamma['down']))\n",
    "            print(form % (chr(0x03C3),self.sigma['up'],self.sigma['down']))\n",
    "            print(form % ('likelihood',l['up'],l['down']))\n",
    "            print(form % ('Extreme quantile',self.extreme_quantile['up'],self.extreme_quantile['down']))\n",
    "            print('\\t' + '-'*ltab*3)\n",
    "        return \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _rootsFinder(fun,jac,bounds,npoints,method):\n",
    "        \"\"\"\n",
    "        Find possible roots of a scalar function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fun : function\n",
    "\t\t    scalar function \n",
    "        jac : function\n",
    "            first order derivative of the function  \n",
    "        bounds : tuple\n",
    "            (min,max) interval for the roots search    \n",
    "        npoints : int\n",
    "            maximum number of roots to output      \n",
    "        method : str\n",
    "            'regular' : regular sample of the search interval, 'random' : uniform (distribution) sample of the search interval\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        numpy.array\n",
    "            possible roots of the function\n",
    "        \"\"\"\n",
    "        if method == 'regular':\n",
    "            step = (bounds[1]-bounds[0])/(npoints+1)\n",
    "            X0 = np.arange(bounds[0]+step,bounds[1],step)\n",
    "        elif method == 'random':\n",
    "            X0 = np.random.uniform(bounds[0],bounds[1],npoints)\n",
    "        \n",
    "        def objFun(X,f,jac):\n",
    "            g = 0\n",
    "            j = np.zeros(X.shape)\n",
    "            i = 0\n",
    "            for x in X:\n",
    "                fx = f(x)\n",
    "                g = g+fx**2\n",
    "                j[i] = 2*fx*jac(x)\n",
    "                i = i+1\n",
    "            return g,j\n",
    "        \n",
    "        opt = minimize(lambda X:objFun(X,fun,jac), X0, \n",
    "                       method='L-BFGS-B', \n",
    "                       jac=True, bounds=[bounds]*len(X0))\n",
    "        \n",
    "        X = opt.x\n",
    "        np.round(X,decimals = 5)\n",
    "        return np.unique(X)\n",
    "    \n",
    "    \n",
    "    def _log_likelihood(Y,gamma,sigma):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood for the Generalized Pareto Distribution (μ=0)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Y : numpy.array\n",
    "\t\t    observations\n",
    "        gamma : float\n",
    "            GPD index parameter\n",
    "        sigma : float\n",
    "            GPD scale parameter (>0)   \n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            log-likelihood of the sample Y to be drawn from a GPD(γ,σ,μ=0)\n",
    "        \"\"\"\n",
    "        n = Y.size\n",
    "        if gamma != 0:\n",
    "            tau = gamma/sigma\n",
    "            L = -n * log(sigma) - ( 1 + (1/gamma) ) * ( np.log(1+tau*Y) ).sum()\n",
    "        else:\n",
    "            L = n * ( 1 + log(Y.mean()) )\n",
    "        return L\n",
    "\n",
    "\n",
    "    def _grimshaw(self,side,epsilon = 1e-8, n_points = 8):\n",
    "        \"\"\"\n",
    "        Compute the GPD parameters estimation with the Grimshaw's trick\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        epsilon : float\n",
    "\t\t    numerical parameter to perform (default : 1e-8)\n",
    "        n_points : int\n",
    "            maximum number of candidates for maximum likelihood (default : 10)\n",
    "        Returns\n",
    "        ----------\n",
    "        gamma_best,sigma_best,ll_best\n",
    "            gamma estimates, sigma estimates and corresponding log-likelihood\n",
    "        \"\"\"\n",
    "        def u(s):\n",
    "            return 1 + np.log(s).mean()\n",
    "            \n",
    "        def v(s):\n",
    "            return np.mean(1/s)\n",
    "        \n",
    "        def w(Y,t):\n",
    "            s = 1+t*Y\n",
    "            us = u(s)\n",
    "            vs = v(s)\n",
    "            return us*vs-1\n",
    "        \n",
    "        def jac_w(Y,t):\n",
    "            s = 1+t*Y\n",
    "            us = u(s)\n",
    "            vs = v(s)\n",
    "            jac_us = (1/t)*(1-vs)\n",
    "            jac_vs = (1/t)*(-vs+np.mean(1/s**2))\n",
    "            return us*jac_vs+vs*jac_us\n",
    "            \n",
    "    \n",
    "        Ym = self.peaks[side].min()\n",
    "        YM = self.peaks[side].max()\n",
    "        Ymean = self.peaks[side].mean()\n",
    "        \n",
    "        \n",
    "        a = -1/YM\n",
    "        if abs(a)<2*epsilon:\n",
    "            epsilon = abs(a)/n_points\n",
    "        \n",
    "        a = a + epsilon\n",
    "        b = 2*(Ymean-Ym)/(Ymean*Ym)\n",
    "        c = 2*(Ymean-Ym)/(Ym**2)\n",
    "    \n",
    "        # We look for possible roots\n",
    "        left_zeros = bidSPOT._rootsFinder(lambda t: w(self.peaks[side],t),\n",
    "                                 lambda t: jac_w(self.peaks[side],t),\n",
    "                                 (a+epsilon,-epsilon),\n",
    "                                 n_points,'regular')\n",
    "        \n",
    "        right_zeros = bidSPOT._rootsFinder(lambda t: w(self.peaks[side],t),\n",
    "                                  lambda t: jac_w(self.peaks[side],t),\n",
    "                                  (b,c),\n",
    "                                  n_points,'regular')\n",
    "    \n",
    "        # all the possible roots\n",
    "        zeros = np.concatenate((left_zeros,right_zeros))\n",
    "        \n",
    "        # 0 is always a solution so we initialize with it\n",
    "        gamma_best = 0\n",
    "        sigma_best = Ymean\n",
    "        ll_best = bidSPOT._log_likelihood(self.peaks[side],gamma_best,sigma_best)\n",
    "        \n",
    "        # we look for better candidates\n",
    "        for z in zeros:\n",
    "            gamma = u(1+z*self.peaks[side])-1\n",
    "            sigma = gamma/z\n",
    "            ll = bidSPOT._log_likelihood(self.peaks[side],gamma,sigma)\n",
    "            if ll>ll_best:\n",
    "                gamma_best = gamma\n",
    "                sigma_best = sigma\n",
    "                ll_best = ll\n",
    "    \n",
    "        return gamma_best,sigma_best,ll_best\n",
    "\n",
    "    \n",
    "\n",
    "    def _quantile(self,side,gamma,sigma):\n",
    "        \"\"\"\n",
    "        Compute the quantile at level 1-q for a given side\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        side : str\n",
    "            'up' or 'down'\n",
    "        gamma : float\n",
    "\t\t    GPD parameter\n",
    "        sigma : float\n",
    "            GPD parameter\n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            quantile at level 1-q for the GPD(γ,σ,μ=0)\n",
    "        \"\"\"\n",
    "        if side == 'up':\n",
    "            r = self.n * self.proba / self.Nt[side]\n",
    "            if gamma != 0:\n",
    "                return self.init_threshold['up'] + (sigma/gamma)*(pow(r,-gamma)-1)\n",
    "            else:\n",
    "                return self.init_threshold['up'] - sigma*log(r)\n",
    "        elif side == 'down':\n",
    "            r = self.n * self.proba / self.Nt[side]\n",
    "            if gamma != 0:\n",
    "                return self.init_threshold['down'] - (sigma/gamma)*(pow(r,-gamma)-1)\n",
    "            else:\n",
    "                return self.init_threshold['down'] + sigma*log(r)\n",
    "        else:\n",
    "            print('error : the side is not right')\n",
    "\n",
    "        \n",
    "    def run(self, with_alarm = True, plot = True):\n",
    "        \"\"\"\n",
    "        Run biDSPOT on the stream\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        with_alarm : bool\n",
    "\t\t    (default = True) If False, SPOT will adapt the threshold assuming \\\n",
    "            there is no abnormal values\n",
    "        Returns\n",
    "        ----------\n",
    "        dict\n",
    "            keys : 'upper_thresholds', 'lower_thresholds' and 'alarms'\n",
    "            \n",
    "            '***-thresholds' contains the extreme quantiles and 'alarms' contains \\\n",
    "            the indexes of the values which have triggered alarms\n",
    "            \n",
    "        \"\"\"\n",
    "        if (self.n>self.init_data.size):\n",
    "            print('Warning : the algorithm seems to have already been run, you \\\n",
    "            should initialize before running again')\n",
    "            return {}\n",
    "        \n",
    "        # actual normal window\n",
    "        W = self.init_data[-self.depth:]\n",
    "        \n",
    "        # list of the thresholds\n",
    "        thup = []\n",
    "        thdown = []\n",
    "        alarm = []\n",
    "        # Loop over the stream\n",
    "        for i in tqdm.tqdm(range(self.data.size)):\n",
    "            Mi = W.mean()\n",
    "            Ni = self.data[i]-Mi\n",
    "            # If the observed value exceeds the current threshold (alarm case)\n",
    "            if Ni>self.extreme_quantile['up'] :\n",
    "                # if we want to alarm, we put it in the alarm list\n",
    "                if with_alarm:\n",
    "                    alarm.append(i)\n",
    "                # otherwise we add it in the peaks\n",
    "                else:\n",
    "                    self.peaks['up'] = np.append(self.peaks['up'],Ni-self.init_threshold['up'])\n",
    "                    self.Nt['up'] += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw('up')\n",
    "                    self.extreme_quantile['up'] = self._quantile('up',g,s)\n",
    "                    W = np.append(W[1:],self.data[i])\n",
    "                    \n",
    "            # case where the value exceeds the initial threshold but not the alarm ones\n",
    "            elif Ni>self.init_threshold['up']:\n",
    "                    # we add it in the peaks\n",
    "                    self.peaks['up'] = np.append(self.peaks['up'],Ni-self.init_threshold['up'])\n",
    "                    self.Nt['up'] += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "                    g,s,l = self._grimshaw('up')\n",
    "                    self.extreme_quantile['up'] = self._quantile('up',g,s)\n",
    "                    W = np.append(W[1:],self.data[i])\n",
    "                    \n",
    "            elif Ni<self.extreme_quantile['down'] :\n",
    "                # if we want to alarm, we put it in the alarm list\n",
    "                if with_alarm:\n",
    "                    alarm.append(i)\n",
    "                # otherwise we add it in the peaks\n",
    "                else:\n",
    "                    self.peaks['down'] = np.append(self.peaks['down'],-(Ni-self.init_threshold['down']))\n",
    "                    self.Nt['down'] += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw('down')\n",
    "                    self.extreme_quantile['down'] = self._quantile('down',g,s)\n",
    "                    W = np.append(W[1:],self.data[i])\n",
    "                    \n",
    "            # case where the value exceeds the initial threshold but not the alarm ones\n",
    "            elif Ni<self.init_threshold['down']:\n",
    "                    # we add it in the peaks\n",
    "                    self.peaks['down'] = np.append(self.peaks['down'],-(Ni-self.init_threshold['down']))\n",
    "                    self.Nt['down'] += 1\n",
    "                    self.n += 1\n",
    "                    # and we update the thresholds\n",
    "\n",
    "                    g,s,l = self._grimshaw('down')\n",
    "                    self.extreme_quantile['down'] = self._quantile('down',g,s)\n",
    "                    W = np.append(W[1:],self.data[i])\n",
    "            else:\n",
    "                self.n += 1\n",
    "                W = np.append(W[1:],self.data[i])\n",
    "\n",
    "                \n",
    "            thup.append(self.extreme_quantile['up']+Mi) # upper thresholds record\n",
    "            thdown.append(self.extreme_quantile['down']+Mi) # lower thresholds record\n",
    "        \n",
    "        return {'upper_thresholds' : thup,'lower_thresholds' : thdown, 'alarms': alarm}\n",
    "    \n",
    "\n",
    "    def plot(self,run_results, with_alarm = True):\n",
    "        \"\"\"\n",
    "        Plot the results given by the run\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        run_results : dict\n",
    "            results given by the 'run' method\n",
    "        with_alarm : bool\n",
    "\t\t    (default = True) If True, alarms are plotted.\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            list of the plots\n",
    "            \n",
    "        \"\"\"\n",
    "        x = range(self.data.size)\n",
    "        K = run_results.keys()\n",
    "        \n",
    "        ts_fig, = plt.plot(x,self.data,color=air_force_blue)\n",
    "        fig = [ts_fig]\n",
    "        \n",
    "        if 'upper_thresholds' in K:\n",
    "            thup = run_results['upper_thresholds']\n",
    "            uth_fig, = plt.plot(x,thup,color=deep_saffron,lw=2,ls='dashed')\n",
    "            fig.append(uth_fig)\n",
    "            \n",
    "        if 'lower_thresholds' in K:\n",
    "            thdown = run_results['lower_thresholds']\n",
    "            lth_fig, = plt.plot(x,thdown,color=deep_saffron,lw=2,ls='dashed')\n",
    "            fig.append(lth_fig)\n",
    "        \n",
    "        if with_alarm and ('alarms' in K):\n",
    "            alarm = run_results['alarms']\n",
    "            if len(alarm)>0:\n",
    "                al_fig = plt.scatter(alarm,self.data[alarm],color='red')\n",
    "                fig.append(al_fig)\n",
    "            \n",
    "        plt.xlim((0,self.data.size))\n",
    "\n",
    "        \n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
